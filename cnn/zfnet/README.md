## ZF-Net

[Visualizing and Understanding Convolutional Networks](<https://cs.nyu.edu/~fergus/papers/zeilerECCV2014.pdf>)

![](https://res.cloudinary.com/chenzhen/image/upload/v1558247633/github_image/2019-05-19/ZFNet.png)

ZF-Net相比于AlexNet，网络结构并没有大的改变，仅仅是调整了一些参数；

如果将第一层卷积的卷积核大小由11改到7，步长从4变成2；

其他如池化的核的大小以及步长，以及卷积核的个数变化，都没有改变；



**文章的主要贡献在于通过使用可视化技术揭示了神经网络各层再干什么，起到了什么作用。**

由于AlexNet的卷积神经网络再ImageNet上取得了开创性的成果，但是对卷积激活函数池化这种卷积网络却没有一个直观的认识，以及为什么卷积神经网络的效果这么好，就完全当作一个黑盒子来使用；作者提出一种新的卷积神经网络可视化技术，提出了ZFNet，并医用反卷积技术做可视化；

反卷积：将激活值映射到原始像素空间；输入是feature map，输出是像素；

三个步骤：反池化、ReLU激活、反卷积

&emsp; 由于最大池化操作是不可逆的，因此可使用一个switch变量来记录每次池化区域中最大值的位置，在反池化的时候，可以近似得到反池化后的结果；

&emsp; ReLU仍然被使用；

&emsp; 反卷积：利用训练好的卷积核对前一层的输入进行卷积得到特征图，反卷积就是将该过程反过来，使用训练好的卷积核对特征图进行卷积，其实这里的卷积核是转置后的；



通过各层卷积核学习到的特征进行可视化，发现神经网络学习到的特征存在层级结构：

* 第二层：学习到边缘核角点检测器；
* 第三层：学习到纹理特征；
* 第四层：对于指定类别图像的一些不变性特征，如狗脸，鸟腿；
* 第五层：得到了目标更显著的特征并获取了位置变化信息；